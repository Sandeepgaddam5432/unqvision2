{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfac UnQVision Video Generation Server\n",
        "\n",
        "This notebook runs the UnQVision backend server on Google Colab, handling all resource-intensive video generation operations. By using Google Colab's free resources, you can process videos without requiring a dedicated server.\n",
        "\n",
        "## \ud83d\udccb Instructions\n",
        "\n",
        "1. Enter your API keys in the form fields below\n",
        "2. Run all cells (Runtime > Run all)\n",
        "3. Follow the Cloudflare authentication process when prompted\n",
        "4. Copy the Cloudflare URL to use with your UnQVision frontend\n",
        "\n",
        "**Note**: The server will run as long as this Colab session is active. Google Colab sessions automatically disconnect after 90 minutes of inactivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd11 API Keys\n",
        "\n",
        "Enter your API keys below. These will be used for text generation, speech synthesis, and fetching stock videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title API Keys\n",
        "google_api_keys = \"YOUR_GOOGLE_API_KEY\" # @param {type:\"string\"}\n",
        "pexels_api_keys = \"YOUR_PEXELS_API_KEY\" # @param {type:\"string\"}\n",
        "\n",
        "# Store API keys securely\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEYS\"] = google_api_keys\n",
        "os.environ[\"PEXELS_API_KEYS\"] = pexels_api_keys\n",
        "\n",
        "# Validate API keys\n",
        "if not google_api_keys or google_api_keys == \"YOUR_GOOGLE_API_KEY\" or len(google_api_keys) < 10:\n",
        "    print(\"\u26a0\ufe0f Warning: Google API key is missing or invalid. You'll need this for text generation and speech synthesis.\")\n",
        "else:\n",
        "    print(\"\u2705 Google API key configured\")\n",
        "    \n",
        "if not pexels_api_keys or pexels_api_keys == \"YOUR_PEXELS_API_KEY\" or len(pexels_api_keys) < 10:\n",
        "    print(\"\u26a0\ufe0f Warning: Pexels API key is missing or invalid. You'll need this for fetching stock videos.\")\n",
        "else:\n",
        "    print(\"\u2705 Pexels API key configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Install Dependencies\n",
        "\n",
        "This section installs all the necessary Python packages for the video generation server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required Python packages\n",
        "!pip install flask flask-cors requests ffmpeg-python --quiet\n",
        "\n",
        "# Download and install the actual cloudflared binary\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 /usr/local/bin/cloudflared\n",
        "\n",
        "# Install FFmpeg if not already available\n",
        "!apt-get update -qq && apt-get install -y ffmpeg\n",
        "\n",
        "# Create temp directory for storing files\n",
        "!mkdir -p /content/temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udda5\ufe0f Flask Server Implementation\n",
        "\n",
        "This section implements the Flask server with endpoints for video generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "\n",
        "import ffmpeg\n",
        "import requests\n",
        "from flask import Flask, jsonify, request, send_from_directory\n",
        "from flask_cors import CORS\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Enable CORS for all routes\n",
        "\n",
        "# Configuration\n",
        "TEMP_DIR = \"/content/temp\"\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "# Global storage for progress updates\n",
        "progress_updates = {}\n",
        "\n",
        "# Helper function to split comma-separated API keys\n",
        "def split_api_keys(api_keys_str):\n",
        "    return [key.strip() for key in api_keys_str.split(',') if key.strip()]\n",
        "\n",
        "# Helper function for retry with different keys\n",
        "def retry_with_keys(operation, api_keys, operation_name):\n",
        "    keys = split_api_keys(api_keys)\n",
        "    if not keys:\n",
        "        raise ValueError(f\"No valid API keys provided for {operation_name}\")\n",
        "    \n",
        "    last_error = None\n",
        "    for i, key in enumerate(keys):\n",
        "        try:\n",
        "            print(f\"Attempting {operation_name} with key #{i+1}...\")\n",
        "            return operation(key)\n",
        "        except Exception as e:\n",
        "            print(f\"Key #{i+1} failed: {str(e)}\")\n",
        "            last_error = e\n",
        "            # If this is not the last key, wait for 1 second before trying the next one.\n",
        "            if i < len(keys) - 1:\n",
        "                print(\"Waiting for 1 second before retrying with the next key...\")\n",
        "                time.sleep(1)\n",
        "    \n",
        "    raise ValueError(f\"All API keys failed for {operation_name}: {str(last_error)}\")\n",
        "\n",
        "# Helper function to add a log message\n",
        "def add_log(session_id, message, log_type='info'):\n",
        "    log_entry = {\n",
        "        'id': int(time.time() * 1000),\n",
        "        'message': message,\n",
        "        'timestamp': datetime.now().strftime('%H:%M:%S'),\n",
        "        'type': log_type\n",
        "    }\n",
        "    \n",
        "    if session_id not in progress_updates:\n",
        "        progress_updates[session_id] = []\n",
        "        \n",
        "    progress_updates[session_id].append(log_entry)\n",
        "    print(f\"[{log_entry['timestamp']}] {message}\")\n",
        "    return log_entry\n",
        "\n",
        "# Function to generate AI director plan\n",
        "def generate_ai_director_plan(prompt, api_keys, session_id):\n",
        "    add_log(session_id, \"\ud83e\udde0 Generating cinematic script with Gemini...\", \"processing\")\n",
        "    \n",
        "    director_prompt = f\"\"\"As an AI Director, create a detailed scene-by-scene plan for a video about: \\\"{prompt}\\\"\\n\\nReturn ONLY a JSON object with this exact structure:\\n\\n{{\\n  \\\"scenes\\\": [\\n    {{\\n      \\\"description\\\": \\\"A detailed description of what happens in this scene\\\",\\n      \\\"searchKeywords\\\": \\\"keywords for finding stock footage\\\",\\n      \\\"duration\\\": 5\\n    }}\\n  ],\\n  \\\"totalDuration\\\": 30\\n}}\\n\\nCreate 6 scenes, each 5 seconds long. Focus on visual, cinematic storytelling.\"\"\"\n",
        "\n",
        "    def ai_director_operation(api_key):\n",
        "        response = requests.post(\n",
        "            f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key={api_key}\",\n",
        "            json={\n",
        "                \"contents\": [{\"parts\": [{\"text\": director_prompt}]}]\n",
        "            },\n",
        "            headers={'Content-Type': 'application/json'}\n",
        "        )\n",
        "        \n",
        "        if response.status_code != 200:\n",
        "            raise ValueError(f\"Failed to generate plan: {response.text}\")\n",
        "        \n",
        "        result = response.json()\n",
        "        plan_text = result.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\")\n",
        "        \n",
        "        if not plan_text:\n",
        "            raise ValueError(\"No plan generated\")\n",
        "        \n",
        "        # Extract JSON from response\n",
        "        import re\n",
        "        json_match = re.search(r'\\{[\\s\\S]*\\}', plan_text)\n",
        "        if not json_match:\n",
        "            raise ValueError(\"Invalid plan format\")\n",
        "        \n",
        "        return json.loads(json_match.group(0))\n",
        "    \n",
        "    return retry_with_keys(ai_director_operation, api_keys, \"AI Director plan generation\")\n",
        "\n",
        "# Function to translate script\n",
        "def translate_script(script, language, api_keys, session_id):\n",
        "    add_log(session_id, f\"\ud83c\udf10 Translating script to {language}...\", \"processing\")\n",
        "    \n",
        "    translate_prompt = f\"\"\"Translate the following script to {language}. Return ONLY the translated text, nothing else:\\n\\n{script}\"\"\"\n",
        "\n",
        "    def translate_operation(api_key):\n",
        "        response = requests.post(\n",
        "            f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key={api_key}\",\n",
        "            json={\n",
        "                \"contents\": [{\"parts\": [{\"text\": translate_prompt}]}]\n",
        "            },\n",
        "            headers={'Content-Type': 'application/json'}\n",
        "        )\n",
        "        \n",
        "        if response.status_code != 200:\n",
        "            raise ValueError(f\"Translation failed: {response.text}\")\n",
        "        \n",
        "        result = response.json()\n",
        "        translated_text = result.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\")\n",
        "        \n",
        "        return translated_text or script\n",
        "    \n",
        "    try:\n",
        "        return retry_with_keys(translate_operation, api_keys, \"Script translation\")\n",
        "    except Exception as e:\n",
        "        print(f\"Translation error: {str(e)}\")\n",
        "        return script  # Fall back to original script on error\n",
        "\n",
        "# Function to generate speech\n",
        "def generate_speech(text, model, api_keys, session_id):\n",
        "    add_log(session_id, \"\ud83c\udfa4 Generating voiceover...\", \"processing\")\n",
        "    \n",
        "    def tts_operation(api_key):\n",
        "        response = requests.post(\n",
        "            f\"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}\",\n",
        "            json={\n",
        "                \"contents\": [{\"parts\": [{\"text\": text}]}],\n",
        "                \"generationConfig\": {\"temperature\": 0.8}\n",
        "            },\n",
        "            headers={'Content-Type': 'application/json'}\n",
        "        )\n",
        "        \n",
        "        if response.status_code != 200:\n",
        "            raise ValueError(f\"TTS generation failed: {response.text}\")\n",
        "        \n",
        "        result = response.json()\n",
        "        candidates = result.get(\"candidates\", [])\n",
        "        \n",
        "        if not candidates or not candidates[0].get(\"content\"):\n",
        "            raise ValueError(\"No audio content generated\")\n",
        "        \n",
        "        # Extract audio data\n",
        "        audio_part = None\n",
        "        for part in candidates[0][\"content\"][\"parts\"]:\n",
        "            if \"audio_data\" in part:\n",
        "                audio_part = part\n",
        "                break\n",
        "        \n",
        "        if not audio_part:\n",
        "            raise ValueError(\"No audio data in response\")\n",
        "        \n",
        "        # Save to file\n",
        "        audio_path = os.path.join(TEMP_DIR, f\"tts_{time.time()}.mp3\")\n",
        "        import base64\n",
        "        with open(audio_path, \"wb\") as f:\n",
        "            f.write(base64.b64decode(audio_part[\"audio_data\"]))\n",
        "        \n",
        "        return audio_path\n",
        "    \n",
        "    return retry_with_keys(tts_operation, api_keys, \"Text-to-speech generation\")\n",
        "\n",
        "# Function to fetch video from Pexels\n",
        "def fetch_pexels_video(keywords, api_keys, session_id):\n",
        "    def pexels_operation(api_key):\n",
        "        response = requests.get(\n",
        "            f\"https://api.pexels.com/videos/search?query={keywords}&per_page=1\",\n",
        "            headers={\"Authorization\": api_key}\n",
        "        )\n",
        "        \n",
        "        if response.status_code != 200:\n",
        "            raise ValueError(f\"Failed to fetch video from Pexels: {response.text}\")\n",
        "        \n",
        "        result = response.json()\n",
        "        video_url = None\n",
        "        \n",
        "        if result.get(\"videos\") and len(result[\"videos\"]) > 0:\n",
        "            # Find a medium-quality video file (not too large, not too small)\n",
        "            video_files = result[\"videos\"][0][\"video_files\"]\n",
        "            # Sort by quality, prioritizing medium quality\n",
        "            video_files.sort(key=lambda x: abs(x.get(\"height\", 0) - 720))\n",
        "            video_url = video_files[0][\"link\"]\n",
        "        \n",
        "        if not video_url:\n",
        "            raise ValueError(\"No video found\")\n",
        "        \n",
        "        # Download video\n",
        "        video_path = os.path.join(TEMP_DIR, f\"pexels_{time.time()}.mp4\")\n",
        "        video_data = requests.get(video_url).content\n",
        "        with open(video_path, \"wb\") as f:\n",
        "            f.write(video_data)\n",
        "        \n",
        "        return video_path\n",
        "    \n",
        "    return retry_with_keys(pexels_operation, api_keys, \"Pexels video fetch\")\n",
        "\n",
        "# Function to concatenate videos with transitions\n",
        "def concatenate_videos(video_paths, session_id):\n",
        "    add_log(session_id, \"\u2702\ufe0f Stitching videos with cinematic transitions...\", \"processing\")\n",
        "    \n",
        "    if not video_paths:\n",
        "        raise ValueError(\"No video paths provided\")\n",
        "    \n",
        "    # If only one video, return it directly\n",
        "    if len(video_paths) == 1:\n",
        "        return video_paths[0]\n",
        "    \n",
        "    output_path = os.path.join(TEMP_DIR, f\"concatenated_{time.time()}.mp4\")\n",
        "    \n",
        "    # Create a complex filter for crossfade transitions\n",
        "    filter_complex = \"\"\n",
        "    inputs = []\n",
        "    \n",
        "    for i, video_path in enumerate(video_paths):\n",
        "        inputs.append(ffmpeg.input(video_path))\n",
        "    \n",
        "    # Simple concatenation for now (ffmpeg-python's xfade is complex)\n",
        "    concat_inputs = []\n",
        "    for i, input_stream in enumerate(inputs):\n",
        "        # Ensure consistent dimensions and framerate\n",
        "        concat_inputs.append(input_stream.video\n",
        "                            .filter('scale', 1280, 720)\n",
        "                            .filter('fps', fps=30))\n",
        "    \n",
        "    # Concatenate all videos\n",
        "    concat = ffmpeg.concat(*concat_inputs, v=1, a=0)\n",
        "    \n",
        "    # Output to file\n",
        "    ffmpeg.output(concat, output_path, vcodec='libx264', preset='fast', crf=23).run()\n",
        "    \n",
        "    return output_path\n",
        "\n",
        "# Function to merge video with audio\n",
        "def merge_video_audio(video_path, audio_path, session_id):\n",
        "    add_log(session_id, \"\ud83c\udfb5 Merging video with voiceover...\", \"processing\")\n",
        "    \n",
        "    output_path = os.path.join(TEMP_DIR, f\"final_{time.time()}.mp4\")\n",
        "    \n",
        "    # Merge video and audio using FFmpeg\n",
        "    ffmpeg.input(video_path).input(audio_path).output(\n",
        "        output_path,\n",
        "        vcodec='copy',  # Don't re-encode video\n",
        "        acodec='aac',   # Use AAC for audio\n",
        "        shortest=None   # Match shortest stream duration\n",
        "    ).run()\n",
        "    \n",
        "    return output_path\n",
        "\n",
        "# Function to generate video\n",
        "def generate_video(config, session_id):\n",
        "    try:\n",
        "        add_log(session_id, \"\u2705 Validating inputs...\", \"success\")\n",
        "        \n",
        "        # Validate inputs\n",
        "        if not config.get(\"projectTitle\") or not config.get(\"mainPrompt\"):\n",
        "            raise ValueError(\"Project title and prompt are required\")\n",
        "        if not config.get(\"googleApiKeys\") or not config.get(\"pexelsApiKeys\"):\n",
        "            raise ValueError(\"API keys are required\")\n",
        "        if not config.get(\"languages\") or len(config[\"languages\"]) == 0:\n",
        "            raise ValueError(\"At least one language must be selected\")\n",
        "        \n",
        "        add_log(session_id, \"\ud83c\udfac Initializing video processing...\", \"processing\")\n",
        "        \n",
        "        # Generate scene plan\n",
        "        scene_plan = generate_ai_director_plan(\n",
        "            config[\"mainPrompt\"], \n",
        "            config[\"googleApiKeys\"],\n",
        "            session_id\n",
        "        )\n",
        "        \n",
        "        # Create script from scenes\n",
        "        script = \" \".join([scene[\"description\"] for scene in scene_plan[\"scenes\"]])\n",
        "        \n",
        "        # Process the first language only (for now)\n",
        "        language = config[\"languages\"][0]\n",
        "        \n",
        "        # Translate the script\n",
        "        translated_script = translate_script(\n",
        "            script, \n",
        "            language, \n",
        "            config[\"googleApiKeys\"],\n",
        "            session_id\n",
        "        )\n",
        "        \n",
        "        # Generate speech\n",
        "        audio_path = generate_speech(\n",
        "            translated_script,\n",
        "            config[\"voiceModel\"],\n",
        "            config[\"googleApiKeys\"],\n",
        "            session_id\n",
        "        )\n",
        "        \n",
        "        # Fetch videos\n",
        "        add_log(session_id, \"\ud83c\udfac Fetching video footage from Pexels...\", \"processing\")\n",
        "        \n",
        "        video_paths = []\n",
        "        for i, scene in enumerate(scene_plan[\"scenes\"]):\n",
        "            add_log(\n",
        "                session_id,\n",
        "                f\"\ud83c\udfac Fetching video {i+1}/{len(scene_plan['scenes'])}: {scene['searchKeywords']}\",\n",
        "                \"processing\"\n",
        "            )\n",
        "            \n",
        "            try:\n",
        "                video_path = fetch_pexels_video(\n",
        "                    scene[\"searchKeywords\"],\n",
        "                    config[\"pexelsApiKeys\"],\n",
        "                    session_id\n",
        "                )\n",
        "                video_paths.append(video_path)\n",
        "            except Exception as e:\n",
        "                # Fallback to main prompt\n",
        "                add_log(\n",
        "                    session_id,\n",
        "                    \"\u26a0\ufe0f Scene-specific video not found, using main prompt...\",\n",
        "                    \"warning\"\n",
        "                )\n",
        "                fallback_path = fetch_pexels_video(\n",
        "                    config[\"mainPrompt\"],\n",
        "                    config[\"pexelsApiKeys\"],\n",
        "                    session_id\n",
        "                )\n",
        "                video_paths.append(fallback_path)\n",
        "        \n",
        "        # Concatenate videos\n",
        "        silent_video_path = concatenate_videos(video_paths, session_id)\n",
        "        \n",
        "        # Merge video with audio\n",
        "        final_video_path = merge_video_audio(silent_video_path, audio_path, session_id)\n",
        "        \n",
        "        # Generate final filename\n",
        "        safe_title = config[\"projectTitle\"].replace(\" \", \"_\").replace(\"/\", \"_\")\n",
        "        final_filename = f\"{safe_title}_{int(time.time())}.mp4\"\n",
        "        final_destination = os.path.join(TEMP_DIR, final_filename)\n",
        "        \n",
        "        # Copy to final destination with proper name\n",
        "        if final_video_path != final_destination:\n",
        "            import shutil\n",
        "            shutil.copy(final_video_path, final_destination)\n",
        "        \n",
        "        add_log(session_id, f\"\u2705 Video for {language} is ready!\", \"success\")\n",
        "        \n",
        "        # Schedule cleanup of temporary files after 1 hour\n",
        "        def cleanup_files():\n",
        "            time.sleep(60 * 60)  # 1 hour\n",
        "            try:\n",
        "                for path in video_paths + [silent_video_path, audio_path, final_video_path]:\n",
        "                    if os.path.exists(path) and path != final_destination:\n",
        "                        os.unlink(path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error during cleanup: {str(e)}\")\n",
        "        \n",
        "        Thread(target=cleanup_files).start()\n",
        "        \n",
        "        return final_filename\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_message = str(e) or \"undefined\"\n",
        "        user_friendly_message = \"Video generation failed due to an unknown error\" if error_message == \"undefined\" else error_message\n",
        "        \n",
        "        add_log(session_id, f\"\u274c Error: {user_friendly_message}\", \"warning\")\n",
        "        raise ValueError(user_friendly_message)\n",
        "\n",
        "# API endpoints\n",
        "@app.route('/generate-video', methods=['POST'])\n",
        "def api_generate_video():\n",
        "    try:\n",
        "        config = request.json\n",
        "        session_id = str(uuid.uuid4())\n",
        "        \n",
        "        # Initialize progress updates for this session\n",
        "        progress_updates[session_id] = []\n",
        "        \n",
        "        # Start video generation in a separate thread\n",
        "        def generate_video_thread():\n",
        "            try:\n",
        "                filename = generate_video(config, session_id)\n",
        "                # Progress updates are collected during generation\n",
        "            except Exception as e:\n",
        "                add_log(session_id, f\"\u274c Error: {str(e)}\", \"warning\")\n",
        "        \n",
        "        thread = Thread(target=generate_video_thread)\n",
        "        thread.start()\n",
        "        \n",
        "        # Return the session ID for polling status\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'sessionId': session_id,\n",
        "            'message': 'Video generation started'\n",
        "        })\n",
        "        \n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            'success': False,\n",
        "            'error': str(e)\n",
        "        }), 500\n",
        "\n",
        "# Endpoint to check generation status\n",
        "@app.route('/generation-status/<session_id>', methods=['GET'])\n",
        "def api_generation_status(session_id):\n",
        "    if session_id not in progress_updates:\n",
        "        return jsonify({\n",
        "            'success': False,\n",
        "            'error': 'Session not found'\n",
        "        }), 404\n",
        "    \n",
        "    updates = progress_updates[session_id]\n",
        "    \n",
        "    # Check if generation is complete\n",
        "    is_complete = False\n",
        "    is_error = False\n",
        "    video_filename = None\n",
        "    \n",
        "    for update in updates:\n",
        "        if update['type'] == 'success' and 'ready' in update['message'].lower():\n",
        "            is_complete = True\n",
        "            # Extract filename from the logs if possible\n",
        "            for u in updates:\n",
        "                if '.mp4' in u['message']:\n",
        "                    parts = u['message'].split()\n",
        "                    for part in parts:\n",
        "                        if '.mp4' in part:\n",
        "                            video_filename = part\n",
        "                            break\n",
        "                    if video_filename:\n",
        "                        break\n",
        "        elif update['type'] == 'warning' and 'error' in update['message'].lower():\n",
        "            is_error = True\n",
        "    \n",
        "    # Find the latest video file if we couldn't determine it from logs\n",
        "    if is_complete and not video_filename:\n",
        "        video_files = [f for f in os.listdir(TEMP_DIR) if f.endswith('.mp4') and f.startswith('final_')]\n",
        "        if video_files:\n",
        "            video_files.sort(key=lambda f: os.path.getmtime(os.path.join(TEMP_DIR, f)), reverse=True)\n",
        "            video_filename = video_files[0]\n",
        "    \n",
        "    return jsonify({\n",
        "        'success': True,\n",
        "        'progressUpdates': updates,\n",
        "        'isComplete': is_complete,\n",
        "        'isError': is_error,\n",
        "        'videoUrl': f'/temp/{video_filename}' if video_filename else None\n",
        "    })\n",
        "\n",
        "# Serve static files\n",
        "@app.route('/temp/<path:filename>')\n",
        "def serve_temp_file(filename):\n",
        "    return send_from_directory(TEMP_DIR, filename)\n",
        "\n",
        "# Status endpoint\n",
        "@app.route('/status', methods=['GET'])\n",
        "def api_status():\n",
        "    return jsonify({\n",
        "        'status': 'Server is running'\n",
        "    })\n",
        "\n",
        "print(\"Flask server code loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 Launch Server with Cloudflare Tunnel\n",
        "\n",
        "This section starts the Flask server and creates a Cloudflare Tunnel to expose it to the internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Function to run the Flask server in the background\n",
        "def run_flask_server():\n",
        "    from flask import Flask, request\n",
        "    app.run(host='localhost', port=8000)\n",
        "\n",
        "# Start Flask server in a separate thread\n",
        "flask_thread = threading.Thread(target=run_flask_server)\n",
        "flask_thread.daemon = True\n",
        "flask_thread.start()\n",
        "\n",
        "print(\"Starting Flask server...\")\n",
        "time.sleep(2)  # Give Flask server time to start\n",
        "\n",
        "# Function to extract the Cloudflare Tunnel URL from output\n",
        "def extract_cloudflare_url(output):\n",
        "    # Look for URLs in the output\n",
        "    url_pattern = r'https://[\\w.-]+\\.trycloudflare\\.com'\n",
        "    match = re.search(url_pattern, output)\n",
        "    if match:\n",
        "        return match.group(0)\n",
        "    return None\n",
        "\n",
        "# Start Cloudflare Tunnel\n",
        "print(\"Starting Cloudflare Tunnel...\")\n",
        "cloudflared_process = subprocess.Popen(\n",
        "    ['cloudflared', 'tunnel', '--url', 'http://localhost:8000'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1\n",
        ")\n",
        "\n",
        "# Wait for the tunnel URL\n",
        "tunnel_url = None\n",
        "start_time = time.time()\n",
        "timeout = 30  # 30 seconds timeout\n",
        "\n",
        "print(\"Waiting for Cloudflare Tunnel to establish...\")\n",
        "while time.time() - start_time < timeout and tunnel_url is None:\n",
        "    output_line = cloudflared_process.stdout.readline().strip()\n",
        "    if output_line:\n",
        "        print(output_line)\n",
        "        tunnel_url = extract_cloudflare_url(output_line)\n",
        "    time.sleep(0.1)\n",
        "\n",
        "if tunnel_url:\n",
        "    print(f\"\\n\\n\ud83d\ude80 Server is running! Your Cloudflare Tunnel URL is:\\n\\n{tunnel_url}\\n\\n\")\n",
        "    print(\"Use this URL to connect your UnQVision frontend.\")\n",
        "    print(\"\\nTo stop the server, interrupt the notebook execution (Runtime > Interrupt execution)\")\n",
        "    \n",
        "    # Keep this cell running to maintain the tunnel\n",
        "    try:\n",
        "        while True:\n",
        "            # Check if cloudflared is still running\n",
        "            if cloudflared_process.poll() is not None:\n",
        "                print(\"\u26a0\ufe0f Cloudflare Tunnel stopped unexpectedly. Restarting...\")\n",
        "                cloudflared_process = subprocess.Popen(\n",
        "                    ['cloudflared', 'tunnel', '--url', 'http://localhost:8000'],\n",
        "                    stdout=subprocess.PIPE,\n",
        "                    stderr=subprocess.STDOUT,\n",
        "                    text=True,\n",
        "                    bufsize=1\n",
        "                )\n",
        "            # Print status every 10 minutes to keep the notebook from timing out\n",
        "            print(f\"\u2705 Server is still running at {tunnel_url} ({time.strftime('%H:%M:%S')})\")\n",
        "            time.sleep(600)  # 10 minutes\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Shutting down server...\")\n",
        "        if cloudflared_process:\n",
        "            cloudflared_process.terminate()\n",
        "else:\n",
        "    print(\"\u274c Failed to start Cloudflare Tunnel within the timeout period.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}